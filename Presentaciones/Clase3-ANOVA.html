<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ANOVA y Tukey</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dra. Stephanie Hereira Pacheco" />
    <script src="Clase3-ANOVA_files/header-attrs-2.30/header-attrs.js"></script>
    <script src="Clase3-ANOVA_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <script src="Clase3-ANOVA_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="Clase3-ANOVA_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="Clase3-ANOVA_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Press Ctrl+C to Copy"})</script>
    <link href="Clase3-ANOVA_files/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
    <link href="Clase3-ANOVA_files/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />
    <link href="Clase3-ANOVA_files/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="Clase3-ANOVA_files/tile-view-0.2.6/tile-view.js"></script>
    <link href="Clase3-ANOVA_files/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="Clase3-ANOVA_files/shareon-1.4.1/shareon.min.js"></script>
    <link href="Clase3-ANOVA_files/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="Clase3-ANOVA_files/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# ANOVA y Tukey
]
.subtitle[
## <img src="logo.jpg" style="width:2in" />
]
.author[
### Dra. Stephanie Hereira Pacheco
]
.institute[
### CICB, UATx
]
.date[
### 09-03-2024
]

---








<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 128px;
z-index: 0;
background-image: url(https://www.ciisder.mx/images/logos/logo_uatx_2019.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:1em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.title-slide):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>





# Contenido

+ Análisis de varianza - ANOVA

+ Pruebas de comaparaciones múltiples para ANOVA

+ Tukey

+ ANOVA de dos vías

+ ANOVA para medidas repetidas

    
---
## Análisis de varianza - ANOVA

&lt;uw-blockquote&gt; Este análisis lo realizamos para medir el **efecto de una o más variables independientes** (cada uno con más de dos niveles) sobre la media de **una variable continua**.

---
## Ejemplo ANOVA - manual

Un profesor quiere saber si tres métodos de enseñanza diferentes (A, B, C) producen notas distintas en un examen. Toma una muestra pequeña de 3 alumnos por método. 
Notas obtenidas (Variable dependiente: Nota | Factor: Método):
- *Método A:* 6, 8, 7
- *Método B:* 9, 10, 8
- *Método C:* 4, 6, 5

---
## Ejemplo ANOVA - manual

- **Paso 1: Formular Hipótesis**

`\(H_{0}\)` (Hipótesis Nula): Las medias son iguales. El método no afecta la nota.

`\(H_{1}\)` (Hipótesis Alternativa): Al menos una media es diferente. Un método es diferente. 

---
## Ejemplo ANOVA - manual

- **Paso 2: Calcular medias de grupos y media general**

Media Método A (`\(\bar{X}_{A}\)`): `\((6+8+7)/3 = 7\)` 

Media Método B (`\(\bar{X}_{B}\)`): `\((9+10+8)/3 = 9\)` 

Media Método C (`\(\bar{X}_{C}\)`): `\((4+6+5)/3 = 5\)` 

Media General (`\(\bar{X}\)`): `\((7+9+5)/3 = 7\)`
---
## Ejemplo ANOVA - manual

- **Paso 3: Calcular Suma de Cuadrados (SC) **

 + **Suma de Cuadrados Entre Grupos (SCT)**: Mide cuánto difieren las medias de los grupos de la media general.

Fórmula: `\(n\Sigma(\bar{x}_{k}-\bar{x})^2\)`

`\(3 * [(7-7)^2 + (9-7)^2 + (5-7)^2]\)`

`\(3 * [(0)^2 + (2)^2 + (-2)^2]\)`

`\(3 * [0+4+4] = 3*8 = 24\)`

---
## Ejemplo ANOVA - manual

 + **Suma de Cuadrados Dentro de Grupos (SCE)**: Mide la variabilidad dentro de cada método.

Fórmula: `\(\Sigma(x_{k}-\bar{x_{k}})^2\)`
 
**Grupo A:** `\((6-7)^2 + (8-7)^2 + (7-7)^2 = 1+1+0 = 2\)`

**Grupo B:**  `\((9-9)^2 + (10-9)^2 + (8-9)^2 = 0+1+1 = 2\)`

**Grupo C:** `\((4-5)^2 + (6-5)^2 + (5-5)^2 = 1+1+0 = 2\)`

 `\(SCE = 2+2+2 = 6\)`
---
## Ejemplo ANOVA - manual

- **Paso 4: Calcular los grados de libertad (gl) **

`\(gl_{entre}= k-1 = 3-1 = 2\)`

`\(gl_{dentro}= N- k= 9-3 = 6\)`

**Paso 5: Calcular Cuadrados Medios**

`\(SCT/k-1 = 24/2 = 12\)`

`\(SCE/N-k = 6/6 = 1\)`


**Paso ¿65: Calcular el estadístico F**

`\(F = 12/1 = 12\)`

---
## Ejemplo ANOVA - manual

**Paso 7: Interpretar el resultado**

F Calculado: 12

F Crítico (Tabla F): Buscamos con 2 y 6 grados de libertad y nivel de confianza 0.05. 
&lt;img src="../images/fdist.png" alt="" width="877" /&gt;

---
## Ejemplo ANOVA - manual

Conclusión: Como F calc &gt; F crit, rechazamos la hipótesis nula.

Significado: Hay una diferencia significativa en las notas dependiendo del método


---


## Pruebas de comparaciones múltiples para ANOVA

&lt;uw-blockquote&gt; *post hoc* viene del latín y significa **para después de esto**. 

&lt;uw-blockquote&gt; Las pruebas *post hoc* se realizan después de que se ha establecido un efecto significativo de un factor

---
## Pruebas de comparaciones múltiples para ANOVA

&lt;uw-blockquote&gt; Se usa para obtener más información sobre la naturaleza de un efecto, es decir, ¿qué niveles del factor están asociados con puntajes más altos o más bajos?

&lt;uw-blockquote&gt; Las pruebas *post hoc* pueden ayudar a contar la historia de los datos más allá de una simple diferencia.
---
## Pruebas de comparaciones múltiples para ANOVA
- Para identificar las diferencias hay que comparar dos a dos las medias de todos los grupos introducidos en el análisis mediante pruebas que comparen 2 grupos, a esto se le conoce como análisis *post-hoc*.

- Los niveles de significancia pueden ser ajustados en función del número de comparaciones. Debido a la inflación del error de tipo I, cuantas más comparaciones se hagan más aumenta la probabilidad de encontrar diferencias significativas. 

---
### Pruebas de comparaciones múltiples para ANOVA
La siguiente tabla ilustra cuántas comparaciones por pares están asociadas con cada número de grupos junto con la tasa de error por familia:

&lt;img src="https://statologos.com/ezoimgfmt/fourpillarfreedom.com/wp-content/uploads/2019/04/post_hoc1.jpg?ezimgfmt=rs:386x298/rscb1/ng:webp/ngcb1" alt="" style="display: block; margin: auto;" /&gt;


---
# Tukey - HSD

&lt;uw-blockquote&gt; La prueba de **diferencia honestamente significativa** (HSD) de Tukey es una forma de determinar si la diferencia entre dos medias de condición es (honestamente) significativa. 

&lt;uw-blockquote&gt; La prueba de Tukey es muy similar a un t-test, excepto que corrige la tasa de error del experimento. Esto lo consigue empleando un estadístico que sigue una distribución llamada **studentized range distribution** en lugar de una distribución t. 

---
# Tukey - HSD

- El estadístico de prueba para la prueba HSD de Tukey es el estadístico de rango estudentizado `\(HSD\)` se define como:
$$
`\begin{aligned}
HSD_{crítico}=q_{crit, \alpha,k, N-k}\sqrt{\frac{CME}{n}}
\end{aligned}`
$$
- Dónde: `\(q_{crit, \alpha,k, N-k}\)` es el valor crítico q, CME es la suma de cuadrados del error calculado anteriormente y n el número de observaciones de un grupo.

- La diferencia entre cada promedio de grupos se compara con el valor obtenido de `\(HSD\)` y los valores mayores que este son considerados significativos.

---
# Tukey - HSD

- La otra forma es calcular el valor observado de `\(q\)` y compararlo directamente con el valor `\(q_{crítico}\)` siguiendo la misma lógica que el valor observado debe ser mayor al valor crítico para ser considerado significativo. La fórmula del valor observado es:
$$
`\begin{aligned}
q_{observado}= \frac{\bar{x_{1}}- \bar{x_{2}}}{\sqrt{\frac{CME}{n}}}
\end{aligned}`
$$




- Para calcular los intervalos de confianza, se realiza con la siguiente fórmula:

$$
`\begin{aligned}
(\bar{x_{1}}-\bar{x_{2}})\pm q_{crit}\sqrt{CME/n}
\end{aligned}`
$$

- Dónde `\(\bar{x_{1}}-\bar{x_{2}}\)` es la diferencia entre las medias de los dos grupos que se están comparando y los demás parámetros son idénticos a los calculados en la fórmula del `\(HSD\)`.

---
## Ejemplo aplicado

| Tratamiento1 | Tratamiento2 | Tratamiento3 | Tratamiento4 |
|:------------:|:------------:|:------------:|:------------:|
|    -3.10     |     7.28     |     0.12     |     8.18     |
|     0.18     |     3.06     |     5.51     |     9.05     |
|    -0.72     |     4.74     |     5.72     |    11.21     |
|     0.09     |     5.29     |     5.93     |     7.31     |
|    -1.66     |     7.88     |     6.56     |     8.83     |
---
## Ejemplo aplicado
.pull-left[

``` r
qcri&lt;-qtukey(p = 0.95, nmeans = 4, df = 16)

sqme&lt;- sqrt(CME/5)

HSD_val&lt;- qcri*sqme


qcri; HSD_val
```

```
## [1] 4.046093
```

```
## [1] 3.469459
```



``` r
dif1&lt;- mean(datos$Tratamiento3)-mean(datos$Tratamiento1)
dif2&lt;- mean(datos$Tratamiento2)-mean(datos$Tratamiento1)
dif3&lt;- mean(datos$Tratamiento4)-mean(datos$Tratamiento1)
dif4&lt;- mean(datos$Tratamiento2)-mean(datos$Tratamiento3)
dif5&lt;- mean(datos$Tratamiento4)-mean(datos$Tratamiento3)
dif6&lt;- mean(datos$Tratamiento4)-mean(datos$Tratamiento2)
```


]

.pull-right[

``` r
dif1&gt;HSD_val;dif2&gt;HSD_val;dif3&gt;HSD_val;dif4&gt;HSD_val;dif5&gt;HSD_val;dif6&gt;HSD_val
```

```
## [1] TRUE
```

```
## [1] TRUE
```

```
## [1] TRUE
```

```
## [1] FALSE
```

```
## [1] TRUE
```

```
## [1] FALSE
```

]

---
## Ejemplo aplicado

``` r
up&lt;-dif1+(qcri*sqme)
low&lt;-dif1-(qcri*sqme)
data.frame(up,low)
```

```
##         up      low
## 1 9.279459 2.340541
```

---
## Ejemplo aplicado


``` r
anov&lt;- aov(Valor~Tratamiento,data = datost)
TukeyHSD(anov, "Tratamiento", ordered = T)
```

```
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
##     factor levels have been ordered
## 
## Fit: aov(formula = Valor ~ Tratamiento, data = datost)
## 
## $Tratamiento
##                            diff        lwr       upr     p adj
## Tratamiento3-Tratamiento1 5.810  2.3405407  9.279459 0.0010334
## Tratamiento2-Tratamiento1 6.692  3.2225407 10.161459 0.0002473
## Tratamiento4-Tratamiento1 9.958  6.4885407 13.427459 0.0000022
## Tratamiento2-Tratamiento3 0.882 -2.5874593  4.351459 0.8847332
## Tratamiento4-Tratamiento3 4.148  0.6785407  7.617459 0.0165968
## Tratamiento4-Tratamiento2 3.266 -0.2034593  6.735459 0.0687136
```
---
## Ejemplo aplicado

.pull-left[

``` r
plot(TukeyHSD(anov, "Tratamiento", ordered = T))
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-12-1.png" alt="" style="display: block; margin: auto;" /&gt;
]

.pull-right[

``` r
library(agricolae)
hsd_agricolae&lt;-HSD.test(anov, "Tratamiento", group = TRUE)
plot(hsd_agricolae)
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-13-1.png" alt="" style="display: block; margin: auto;" /&gt;

]
---
### Newman-Keuls (student)

+ Es una prueba *post hoc* para probar las diferencias en las medias de varios grupos. Se realiza después que una ANOVA haya dado significativo y sé usa para identificar qué par de medias son diferentes. La prueba se basa también en la **distribución de rango estudentizada**.

- El método Newman-Keuls fue introducido por Newman en 1939 y desarrollado por Keuls en 1952.

+ Las hipótesis que manjea son:
 - `\(H_{o}\)`: media 1 = media 2
 - `\(H_{a}\)`: media 1 ≠ media 2

---
#### Newman-Keuls
1. Ordenar las medias de la más grande a la más pequeña.
2. Calcular el error estándar como anteriormente `\(\sqrt{\frac{CME}{n}}\)`
3. Cacular el valor crítico *q* con la fórmula:
`\(q_{crítico} = \frac{\bar{x_{1}}-\bar{x_{2}}}{S_{12}}\)`
4. Encontrar el valor crítico en la tabla de valores críticos con los `\(k\)` y los grados de libertad del error. [Tabla1](https://elvers.us/stats/tables/qprobability.html), [Tabla2](https://www.statisticshowto.com/studentized-range-distribution/#qtable) <svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#103261;overflow:visible;position:relative;"><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5c-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6c31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0c-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0L579.8 267.7zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5c50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5L217.7 177.2c31.5-31.5 82.5-31.5 114 0c27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg>
  - Si las dos primeras medias no son diferentes entonces para la prueba
  - Si la dos primeras son diferentes sigue con los siguientes pares de medias desde el paso 2, para cuando no encuentres diferencias.
5. En cada comparación de medias corrige los grados de libertad según el número de grupos comparados. 

---
#[Newman-Keuls](https://methods.sagepub.com/reference/encyc-of-research-design/n266.xml) <svg aria-hidden="true" role="img" viewBox="0 0 640 512" style="height:1em;width:1.25em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:#103261;overflow:visible;position:relative;"><path d="M579.8 267.7c56.5-56.5 56.5-148 0-204.5c-50-50-128.8-56.5-186.3-15.4l-1.6 1.1c-14.4 10.3-17.7 30.3-7.4 44.6s30.3 17.7 44.6 7.4l1.6-1.1c32.1-22.9 76-19.3 103.8 8.6c31.5 31.5 31.5 82.5 0 114L422.3 334.8c-31.5 31.5-82.5 31.5-114 0c-27.9-27.9-31.5-71.8-8.6-103.8l1.1-1.6c10.3-14.4 6.9-34.4-7.4-44.6s-34.4-6.9-44.6 7.4l-1.1 1.6C206.5 251.2 213 330 263 380c56.5 56.5 148 56.5 204.5 0L579.8 267.7zM60.2 244.3c-56.5 56.5-56.5 148 0 204.5c50 50 128.8 56.5 186.3 15.4l1.6-1.1c14.4-10.3 17.7-30.3 7.4-44.6s-30.3-17.7-44.6-7.4l-1.6 1.1c-32.1 22.9-76 19.3-103.8-8.6C74 372 74 321 105.5 289.5L217.7 177.2c31.5-31.5 82.5-31.5 114 0c27.9 27.9 31.5 71.8 8.6 103.9l-1.1 1.6c-10.3 14.4-6.9 34.4 7.4 44.6s34.4 6.9 44.6-7.4l1.1-1.6C433.5 260.8 427 182 377 132c-56.5-56.5-148-56.5-204.5 0L60.2 244.3z"/></svg>

&lt;img src="images/new.jpg" alt="" width="1000" /&gt;


---


``` r
library(agricolae)
SNK.test(anov, "Tratamiento", console = TRUE)
```

```
## 
## Study: anov ~ "Tratamiento"
## 
## Student Newman Keuls Test
## for Valor 
## 
## Mean Square Error:  3.676393 
## 
## Tratamiento,  means
## 
##               Valor      std r        se   Min   Max   Q25   Q50  Q75
## Tratamiento1 -1.042 1.368912 5 0.8574838 -3.10  0.18 -1.66 -0.72 0.09
## Tratamiento2  5.650 1.955479 5 0.8574838  3.06  7.88  4.74  5.29 7.28
## Tratamiento3  4.768 2.627845 5 0.8574838  0.12  6.56  5.51  5.72 5.93
## Tratamiento4  8.916 1.449890 5 0.8574838  7.31 11.21  8.18  8.83 9.05
## 
## Alpha: 0.05 ; DF Error: 16 
## 
## Critical Range
##        2        3        4 
## 2.570735 3.129078 3.469459 
## 
## Means with the same letter are not significantly different.
## 
##               Valor groups
## Tratamiento4  8.916      a
## Tratamiento2  5.650      b
## Tratamiento3  4.768      b
## Tratamiento1 -1.042      c
```

---


``` r
library(agricolae)
snk&lt;-SNK.test(anov, "Tratamiento", console = FALSE)
plot(snk)
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-16-1.png" alt="" style="display: block; margin: auto;" /&gt;





---
## Tukey-HSD vs Newman-Keuls

- Aunque el punto importante de las pruebas *post hoc* es disminuir los errores tipo I, en algunos casos Newman-Keuls con más de 4 grupos incrementa ligeramente este tipo de error en mayor medida que Tukey-HSD.

- Newman-Keuls trabaja de forma secuencial por lo que por esta razón no puede producir intervalos de confianza al 95% para cada diferencia ni valores de p justados como lo hace Tukey-HSD.

- Newman-Keuls es más conservadora que Tukey-HSD por su umbral móvil y el valor de alfa o significancia es el mismo del ANOVA (0.05).

---
## Prueba de Duncan

+ Es una variante de Newman-Keuls pero a diferencia de esta, usa niveles de alfa que se van incrementando en cada paso del procedimiento, siendo menos suceptible a errores de Tipo I.

- Fue propuesto por David B. Duncan en 1955 como una modificación del método anterior pero con más poder estadístico. 

- El resultado de la prueba es un conjunto de subconjuntos de medias, donde en cada subconjunto se ha encontrado que las medias no son significativamente diferentes entre sí.

- Tiene los mismos supuestos que las anteriores y requiere un resultado significativo en el ANOVA.



---
### Prueba de Duncan
1. Ordenar las medias de la más grande a la más pequeña.
2. Cacular el valor crítico *q*, aquí denominad como `\(r\)`, como las pruebas anteriores
3. Encontrar el valor crítico en la tabla de valores críticos con los `\(k\)` y los grados de libertad del error. 
4. Calcular el valor crítico de Duncan, denotado por:

$$
`\begin{aligned}
R_{(k,\nu,\alpha_{p})}=r_{k, \alpha_{p},k, v}\sqrt{\frac{CME}{n}}
\end{aligned}`
$$

---
### Prueba de Duncan

- Este `\(r\)` (antes `\(q_{crítico}\)`) es variable como anteriormente vimos en la prueba de Newman-Keuls y las diferencias de los promedios:
  - Si las dos primeras medias no son diferentes entonces para la prueba
  - Si la dos primeras son diferentes sigue con los siguientes pares de medias desde el paso 2, para cuando no encuentres diferencias.
  - En cada comparación de medias corrige los grados de libertad por comparaciones

---
### Prueba de Duncan
Además de estos pasos que lucen muy parecidos a la prueba de Newman-Keuls este método introduce además una significancia o `\(\alpha\)` variable, esto como un **"nivel de protección"**:

$$
`\begin{aligned}
\alpha_{p}=1-(1-\alpha)^K-1
\end{aligned}`
$$

||Nivel de protección alfa| probabilidad de error tipo I|
|:-:|:-----------------------:|:-----------------------------:|
|k=2|0.95|0.05|
|k=3|0.95|0.097|
|k=4|0.95|0.143|
|k=5|0.95|0.185|
|k=6|0.95|0.226|

---


``` r
library(agricolae)
duncan.test(anov, "Tratamiento", console = TRUE)
```

```
## 
## Study: anov ~ "Tratamiento"
## 
## Duncan's new multiple range test
## for Valor 
## 
## Mean Square Error:  3.676393 
## 
## Tratamiento,  means
## 
##               Valor      std r        se   Min   Max   Q25   Q50  Q75
## Tratamiento1 -1.042 1.368912 5 0.8574838 -3.10  0.18 -1.66 -0.72 0.09
## Tratamiento2  5.650 1.955479 5 0.8574838  3.06  7.88  4.74  5.29 7.28
## Tratamiento3  4.768 2.627845 5 0.8574838  0.12  6.56  5.51  5.72 5.93
## Tratamiento4  8.916 1.449890 5 0.8574838  7.31 11.21  8.18  8.83 9.05
## 
## Alpha: 0.05 ; DF Error: 16 
## 
## Critical Range
##        2        3        4 
## 2.570735 2.695760 2.773913 
## 
## Means with the same letter are not significantly different.
## 
##               Valor groups
## Tratamiento4  8.916      a
## Tratamiento2  5.650      b
## Tratamiento3  4.768      b
## Tratamiento1 -1.042      c
```


---

``` r
library(agricolae)
duncan&lt;-agricolae::duncan.test(anov, "Tratamiento")
plot(duncan)
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-18-1.png" alt="" style="display: block; margin: auto;" /&gt;


---
# Duncan vs Newman-Keuls

- La prueba de Duncan está basado en Newman-Keuls, éste último no protege la tasa de error familiar (tipo I) como Duncan con su alfa variable

- La prueba de Duncan entonces intencionalmente sube los niveles del alfa en cada paso del procedimiento de Newman-Keuls

- Por estas subidas de los alfas muchos critican esta prueba por ser muy liberal 

---
## Otras pruebas...

- Prueba de Dunnet : comparar con un control

- Prueba de Scheffé: se aplica también con datos no balanceados

- Prueba de Fisher (LSD): mismo principio de Duncan pero con la distribución t. 

- Tukey-Kramer: para datos desbalanceados.

- Pruebas pareadas (t.test) con correcciones: Bonferroni, Holm-Bonferroni, FDR, entre otras. 

---

## 1 variable cuantitativa &gt;2 grupos dependientes: ANOVA por bloques 

``` r
library(BHH2)
data(penicillin.data)
penicilina&lt;- penicillin.data
str(penicilina)
```

```
## 'data.frame':	20 obs. of  4 variables:
##  $ blend: Factor w/ 5 levels "B1","B2","B3",..: 1 2 3 4 5 1 2 3 4 5 ...
##  $ run  : int  1 4 2 1 3 3 2 1 3 4 ...
##  $ treat: Factor w/ 4 levels "A","B","C","D": 1 1 1 1 1 2 2 2 2 2 ...
##  $ yield: int  89 84 81 87 79 88 77 87 92 81 ...
```
---

``` r
plot(yield~blend+treat, data = penicilina)
```

![](Clase3-ANOVA_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;![](Clase3-ANOVA_files/figure-html/unnamed-chunk-20-2.png)&lt;!-- --&gt;
---

``` r
modelo3&lt;- lm(yield~blend+treat, data = penicilina)
```


``` r
par(mfrow = c(2, 2))
plot(modelo3)
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-22-1.png" alt="" style="display: block; margin: auto;" /&gt;

---
# Anova por bloques


``` r
anova(lm(yield~ blend+treat,data = penicilina))
```

```
## Analysis of Variance Table
## 
## Response: yield
##           Df Sum Sq Mean Sq F value  Pr(&gt;F)  
## blend      4    264  66.000  3.5044 0.04075 *
## treat      3     70  23.333  1.2389 0.33866  
## Residuals 12    226  18.833                  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
---

## ANOVA 2 factores fijos sin interacción y con interacción

Modelo aditivo, efectos fijos: aov(variable_respuesta \~ factor1 + factor2, data)

Modelo con interacción: aov(variable_respuesta \~ factor1 x factor2, data)

Modelo solo interacción: aov(variable_respuesta \~ factor1 : factor2, data)


---
### Ejemplo ANOVA 2 vías

Para este ejemplo usaremos el set de datos 'ToothGrowth'


``` r
data("ToothGrowth")
dientes&lt;- ToothGrowth
str(dientes)
```

```
## 'data.frame':	60 obs. of  3 variables:
##  $ len : num  4.2 11.5 7.3 5.8 6.4 10 11.2 11.2 5.2 7 ...
##  $ supp: Factor w/ 2 levels "OJ","VC": 2 2 2 2 2 2 2 2 2 2 ...
##  $ dose: num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...
```

Como podemos observar la variable de respuesta aquí sería la longitud de los dientes y los factores a evaluar son *'supp'* y *'dose'*, *supp* es la forma en que le dieron la vitamina C a los cerdos, si como OJ (jugo de naranja) o AS (ácido ascórbico) a diferentes dosis (*dose*) de 0.5, 1 y 2 mg/día.
---
### Ejemplo ANOVA 2 vías

El factor 'dose' o dosis no aparece como factor sino como variable numérica.

Esto puede ser un inconveniente al correr el ANOVA así que modificaremos esto en la data.



``` r
dientes$dose &lt;- factor(dientes$dose, 
                  levels = c(0.5, 1, 2),
                  labels = c("D0.5", "D1", "D2"))
head(dientes)
```

```
##    len supp dose
## 1  4.2   VC D0.5
## 2 11.5   VC D0.5
## 3  7.3   VC D0.5
## 4  5.8   VC D0.5
## 5  6.4   VC D0.5
## 6 10.0   VC D0.5
```

---
### Ejemplo ANOVA 2 vías

Bien, visualizaremos nuestros datos para ver las tendencias de nuestros factores sobre nuestra variable de respuesta:

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-26-1.png" alt="" width="45%" /&gt;&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-26-2.png" alt="" width="45%" /&gt;

---
### Ejemplo ANOVA 2 vías

.pull-left[

``` r
ggboxplot(data = ToothGrowth, x = "dose", y = "len", fill = "supp")
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-27-1.png" alt="" width="80%" style="display: block; margin: auto;" /&gt;
]

.pull-right[

``` r
ggline(ToothGrowth, x = "dose", y = "len", color = "supp", add = c("mean_se", "jitter"))
```

![](Clase3-ANOVA_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;
]

---
### Ejemplo ANOVA 2 vías

Como pudimos ver aparentemente los factores podrían tener una interacción, en este caso podríamos correr una ANOVA dos vías o bien aditivo o bien mutiplicativo si queremos confirmar la interacción, o bien solo ver la interacción.


``` r
anova1&lt;- aov(len ~ supp + dose, data = dientes)
anova2&lt;-  aov(len ~ supp * dose, data = dientes)
anova3&lt;-  aov(len ~ supp : dose, data = dientes)
```


``` r
summary(anova1)
```

```
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## supp         1  205.4   205.4   14.02 0.000429 ***
## dose         2 2426.4  1213.2   82.81  &lt; 2e-16 ***
## Residuals   56  820.4    14.7                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
### Ejemplo ANOVA 2 vías


``` r
summary(anova2)
```

```
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## supp         1  205.4   205.4  15.572 0.000231 ***
## dose         2 2426.4  1213.2  92.000  &lt; 2e-16 ***
## supp:dose    2  108.3    54.2   4.107 0.021860 *  
## Residuals   54  712.1    13.2                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```



``` r
summary(anova3)
```

```
##             Df Sum Sq Mean Sq F value Pr(&gt;F)    
## supp:dose    5 2740.1   548.0   41.56 &lt;2e-16 ***
## Residuals   54  712.1    13.2                   
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
## ANOVA 2 factores de efectos aleatorios/mixtos


``` r
library(faraway)
data(rabbit)
conejos&lt;- rabbit
str(conejos)
```

```
## 'data.frame':	30 obs. of  3 variables:
##  $ treat: Factor w/ 6 levels "a","b","c","d",..: 6 2 3 3 1 2 3 6 4 1 ...
##  $ gain : num  42.2 32.6 35.2 40.9 40.1 38.1 34.6 34.3 37.5 44.9 ...
##  $ block: Factor w/ 10 levels "b1","b10","b2",..: 1 1 1 3 3 3 4 4 4 5 ...
```

---

``` r
plot(gain~ block + treat, rabbit, col=456)
```

![](Clase3-ANOVA_files/figure-html/unnamed-chunk-34-1.png)&lt;!-- --&gt;![](Clase3-ANOVA_files/figure-html/unnamed-chunk-34-2.png)&lt;!-- --&gt;
---


``` r
#Observamos que tanto el bloque como el tratamiento son significativos.
lm.rabbit &lt;- lm(gain~ block+treat, data=rabbit)
anova(lm.rabbit)
```

```
## Analysis of Variance Table
## 
## Response: gain
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## block      9 730.39  81.154  8.0738 0.0002454 ***
## treat      5 158.73  31.745  3.1583 0.0381655 *  
## Residuals 15 150.77  10.052                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
---

``` r
# nos interesa analizar el efecto del factor (dieta) sobre la respuesta una vez que se haya tenido en cuenta la variabilidad atribuible al bloque (camada).
library(nlme)
lme.rabbit1 &lt;- lme(gain~ treat, random=~1|block, data=rabbit)
anova(lme.rabbit1)
```

```
##             numDF denDF  F-value p-value
## (Intercept)     1    15 590.5297  &lt;.0001
## treat           5    15   3.2818  0.0336
```

---
## ANOVA 2 factores anidados 


``` r
df&lt;-data.frame(crecimiento = c (13, 16, 16, 12, 15, 16, 19, 16, 15, 15, 12, 15,
                          19, 19, 20, 22, 23, 18, 16, 18, 19, 20, 21, 21,
                          21, 23, 24, 22, 25, 20, 20, 22, 24, 22, 25, 26),
                 fertilizante = factor(c(rep(c(' A ', ' B ', ' C '), each=12 ))),
                 tech = factor(c(rep(1: 9,  each=4 ))))
```


``` r
str(df)
```

```
## 'data.frame':	36 obs. of  3 variables:
##  $ crecimiento : num  13 16 16 12 15 16 19 16 15 15 ...
##  $ fertilizante: Factor w/ 3 levels " A "," B "," C ": 1 1 1 1 1 1 1 1 1 1 ...
##  $ tech        : Factor w/ 9 levels "1","2","3","4",..: 1 1 1 1 2 2 2 2 3 3 ...
```

---


``` r
summary(aov(crecimiento ~ fertilizante/tech, data = df))
```

```
##                   Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## fertilizante       2  372.7  186.33  53.238 4.27e-10 ***
## fertilizante:tech  6   31.8    5.31   1.516    0.211    
## Residuals         27   94.5    3.50                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


``` r
summary(aov(crecimiento ~ fertilizante %in% tech, data = df))
```

```
##                   Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## fertilizante:tech  8  404.5   50.56   14.45 6.06e-08 ***
## Residuals         27   94.5    3.50                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
---
## ANOVA 2 factores fijos parcelas divididas (split plot)

En este experimento, se desean medir los efectos de tres factores sobre la cantidad de glucógeno en el hígado de ratas. En este experimento, hay 6 ratas (parcelas o plots). 
A cada rata, se le asignó al azar una de las tres dietas alimentarias (T1, T2 y T3).
De cada rata, se le extrajo el hígado y se dividió en cuatro segmentos. Cada segmento se preparó utilizando uno de dos productos químicos diferentes (P1 y P2). Finalmente, se midió el nivel de glucógeno de cada pedazo de hígado usando dos técnicas analíticas diferentes (A y B). La unidad experimental de la dieta es la rata. La unidad experimental para la preparación química del hígado es una tira de hígado. La unidad experimental de la técnica analítica es un trozo de hígado. Todos son diferentes.

---
## ANOVA 2 factores fijos parcelas divididas (split plot)


``` r
ratas&lt;- readr::read_csv("https://raw.githubusercontent.com/Steph0522/Curso_Bioestadistica_2023/main/Modulo2/data_ratas.csv")
str(ratas)
```

```
## spc_tbl_ [48 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)
##  $ glycogen: num [1:48] 127 126 127 121 124 125 132 138 146 144 ...
##  $ food    : chr [1:48] "T1" "T1" "T1" "T1" ...
##  $ rat     : chr [1:48] "Remy" "Remy" "Remy" "Remy" ...
##  $ prep    : chr [1:48] "P1" "P1" "P2" "P2" ...
##  $ method  : chr [1:48] "A" "B" "A" "B" ...
##  - attr(*, "spec")=
##   .. cols(
##   ..   glycogen = col_double(),
##   ..   food = col_character(),
##   ..   rat = col_character(),
##   ..   prep = col_character(),
##   ..   method = col_character()
##   .. )
##  - attr(*, "problems")=&lt;externalptr&gt;
```
---
## ANOVA 2 factores fijos parcelas divididas (split plot)


``` r
anova_factorial &lt;- lm(glycogen ~ food * prep * method, data = ratas)
anova(anova_factorial)
```

```
## Analysis of Variance Table
## 
## Response: glycogen
##                  Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## food              2 3530.0 1765.02 32.2583 9.401e-09 ***
## prep              1   35.0   35.02  0.6401    0.4289    
## method            1   54.2   54.19  0.9904    0.3263    
## food:prep         2  133.3   66.65  1.2180    0.3077    
## food:method       2    5.4    2.69  0.0491    0.9521    
## prep:method       1   11.0   11.02  0.2014    0.6563    
## food:prep:method  2    5.3    2.65  0.0484    0.9529    
## Residuals        36 1969.7   54.72                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
---

``` r
anova_split &lt;- aov(glycogen ~ food * prep * method + Error(rat/food:prep), data = ratas)
summary(anova_split)
```

```
## 
## Error: rat
##           Df Sum Sq Mean Sq F value Pr(&gt;F)  
## food       2   3530  1765.0    6.22 0.0856 .
## Residuals  3    851   283.8                 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Error: rat:food:prep
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## prep       1   35.0   35.02   0.269  0.640
## food:prep  2  133.3   66.65   0.513  0.643
## Residuals  3  390.1  130.02               
## 
## Error: Within
##                  Df Sum Sq Mean Sq F value Pr(&gt;F)
## method            1   54.2   54.19   2.232  0.146
## food:method       2    5.4    2.69   0.111  0.896
## prep:method       1   11.0   11.02   0.454  0.506
## food:prep:method  2    5.3    2.65   0.109  0.897
## Residuals        30  728.4   24.28
```


---

## Análisis de medidas repetidas


Queremos realizar un análisis de medidas repetidas para los datos de rendimiento académico de seis alumnos. En cada alumno se ha medido a cinco tiempos diferentes su rendimiento, por tanto las muestras tomadas no son independientes entre si. Para poder analizar estos datos debemos considerar las muestras como relacionadas, es decir debemos realizar un ANOVA de medidas repetidas.\


``` r
individuos&lt;- factor(c(rep(1,5), rep(2,5), rep(3, 5),
                      rep(4, 5), rep(5,5), rep(6,5)))
tiempo&lt;- factor(rep(1:5, 6))
rendimiento&lt;- c(8.5, 8.2,8.9, 7.7, 7.4,
                9.8,8.9,8.9,8.8,8.1,
                9.6,9.0, 9.3, 7.5, 7.1,
                7.5, 7.8, 7.8, 4.5, 4.6,
                5.8, 5.8, 5.9, 2.6, 1.2,
                9.9, 9.8, 9.6, 8.6, 8.7)
data_rendimiento&lt;- data.frame(individuos=individuos,
                              tiempo=tiempo, rendimiento=rendimiento)
```
---
## Análisis de medidas repetidas


``` r
str(data_rendimiento)
```

```
## 'data.frame':	30 obs. of  3 variables:
##  $ individuos : Factor w/ 6 levels "1","2","3","4",..: 1 1 1 1 1 2 2 2 2 2 ...
##  $ tiempo     : Factor w/ 5 levels "1","2","3","4",..: 1 2 3 4 5 1 2 3 4 5 ...
##  $ rendimiento: num  8.5 8.2 8.9 7.7 7.4 9.8 8.9 8.9 8.8 8.1 ...
```
---
## Análisis de medidas repetidas

Vamos a realizar el análisis de medidas repetidas ANOVA paramétrico por medio del paquete ez. Para ello hay que indicar nuestros datos (data), nuestra variable (dv), nuestros individuos (wid) y el tiempo (within):

---
## Análisis de medidas repetidas

**Versión paramétrica:**


``` r
library(ez)
ezANOVA(data=data_rendimiento, dv=rendimiento, wid=individuos, within=tiempo)
```

```
## $ANOVA
##   Effect DFn DFd        F            p p&lt;.05       ges
## 2 tiempo   4  20 12.41317 3.096979e-05     * 0.2211562
## 
## $`Mauchly's Test for Sphericity`
##   Effect           W          p p&lt;.05
## 2 tiempo 0.003212948 0.03413309     *
## 
## $`Sphericity Corrections`
##   Effect       GGe       p[GG] p[GG]&lt;.05       HFe       p[HF] p[HF]&lt;.05
## 2 tiempo 0.3126606 0.009730034         * 0.3669864 0.006076078         *
```


Podemos ver en nuestros resultados que el tiempo es significativo, es decir, el rendimiento escolar cambia con el tiempo. Pero en este caso nuestros datos violan uno de los requisitos que es la esfericidad (test de Mauchly significativo), debemos fiarnos de la p de la **Sphericity corrections** que nos confirma lo que hemos deducido al principio.
---
## Análisis de medidas repetidas


``` r
boxplot(rendimiento~tiempo, xlab="tiempo", 
        ylab="Rendimiento académico", 
        main="rendimiento alumnos con el paso del tiempo",
        col="blue", data=data_rendimiento)
```

&lt;img src="Clase3-ANOVA_files/figure-html/unnamed-chunk-47-1.png" alt="" width="80%" style="display: block; margin: auto;" /&gt;
---
## Análisis de medidas repetidas

**Versión no paramétrica:**\


``` r
library(tidyverse)
library(jmv)
#cambiamos el formato de la data
data_rendimiento_notidy&lt;-data_rendimiento %&gt;% mutate(tiempo =case_when(
  tiempo== 1 ~ "T1",
  tiempo== 2 ~ "T2",
  tiempo== 3 ~ "T3",
  tiempo== 4 ~ "T4",
  tiempo== 5 ~ "T5")) %&gt;% pivot_wider(names_from =tiempo, 
                                      values_from = rendimiento )

jmv::anovaRMNP(data_rendimiento_notidy, measures=vars(T1,T2,T3,T4,T5))
```
---
### El día de hoy aprendimos que...
- Se utiliza un ANOVA para determinar si existe o no una diferencia estadísticamente significativa entre las medias de tres o más grupos independientes. Y hay de varios tipos.

- Si un ANOVA produce un valor p que es menor que nuestro nivel de significancia, podemos usar pruebas *post hoc* para averiguar qué medias de grupo difieren entre sí.

---
### El día de hoy aprendimos que...

- Las pruebas *post hoc* nos permiten controlar la tasa de error familiar mientras realizamos múltiples comparaciones por pares.
- La compensación de controlar la tasa de error familiar es un poder estadístico más bajo. Podemos reducir los efectos de un poder estadístico más bajo haciendo menos comparaciones por pares.
- Debe determinar de antemano en qué grupos le gustaría hacer comparaciones por pares y qué prueba post hoc utilizará para hacerlo.


---
## Referencias y material suplementario

- [Advanced Statistics I 2021 Edition](https://bookdown.org/danbarch/psy_207_advanced_stats_I/differences-between-two-things.html#sign-binomial-test)

- [Pruebas paramétricas y no paramétricas](https://enviromigration.files.wordpress.com/2016/04/pruebas-paramc3a9tricas-y-no-parametricas.pdf)

- [Estadística paramétrica y no paramétrica](https://rstudio-pubs-static.s3.amazonaws.com/724751_c45a17f9e45f464c93e94f3fb0c6d340.html#16)

- [Prácticos de bioestadística 2](https://derek-corcoran-barrios.github.io/AyduantiaStats/_book/t-student.html)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
