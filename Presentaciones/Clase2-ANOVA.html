<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ANOVA</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dra. Stephanie Hereira Pacheco" />
    <script src="Clase2-ANOVA_files/header-attrs-2.30/header-attrs.js"></script>
    <script src="Clase2-ANOVA_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <script src="Clase2-ANOVA_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="Clase2-ANOVA_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="Clase2-ANOVA_files/xaringanExtra-clipboard-0.2.6/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"Press Ctrl+C to Copy"})</script>
    <link href="Clase2-ANOVA_files/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
    <link href="Clase2-ANOVA_files/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />
    <link href="Clase2-ANOVA_files/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="Clase2-ANOVA_files/tile-view-0.2.6/tile-view.js"></script>
    <link href="Clase2-ANOVA_files/shareon-1.4.1/shareon.min.css" rel="stylesheet" />
    <script src="Clase2-ANOVA_files/shareon-1.4.1/shareon.min.js"></script>
    <link href="Clase2-ANOVA_files/xaringanExtra-shareagain-0.2.6/shareagain.css" rel="stylesheet" />
    <script src="Clase2-ANOVA_files/xaringanExtra-shareagain-0.2.6/shareagain.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# ANOVA
]
.subtitle[
## <img src="logo.jpg" style="width:2in" />
]
.author[
### Dra. Stephanie Hereira Pacheco
]
.institute[
### CICB, UATx
]
.date[
### 02-03-2024
]

---








<div>
<style type="text/css">.xaringan-extra-logo {
width: 110px;
height: 128px;
z-index: 0;
background-image: url(https://www.ciisder.mx/images/logos/logo_uatx_2019.png);
background-size: contain;
background-repeat: no-repeat;
position: absolute;
top:1em;right:1em;
}
</style>
<script>(function () {
  let tries = 0
  function addLogo () {
    if (typeof slideshow === 'undefined') {
      tries += 1
      if (tries < 10) {
        setTimeout(addLogo, 100)
      }
    } else {
      document.querySelectorAll('.remark-slide-content:not(.title-slide):not(.inverse):not(.hide_logo)')
        .forEach(function (slide) {
          const logo = document.createElement('div')
          logo.classList = 'xaringan-extra-logo'
          logo.href = null
          slide.appendChild(logo)
        })
    }
  }
  document.addEventListener('DOMContentLoaded', addLogo)
})()</script>
</div>





# Contenido

+ An√°lisis de varianza - ANOVA

+ Pruebas param√©tricas y supuestos estad√≠sticos

+ Supuestos del ANOVA

+ ANOVA de una v√≠a

    
---
## An√°lisis de varianza - ANOVA

&lt;uw-blockquote&gt; La t√©cnica de an√°lisis de varianza (**ANOVA**) tambi√©n conocida como an√°lisis factorial y desarrollada por Fisher en 1930

&lt;uw-blockquote&gt; Este an√°lisis constituye la herramienta b√°sica para el estudio del **efecto de una o m√°s variables independientes** (cada uno con dos o m√°s niveles) sobre la media de **una variable continua**. 

---
## An√°lisis de varianza - ANOVA

&lt;uw-blockquote&gt;El an√°lisis de varianza nos permite evaluar el efecto de `\(k\)` variables independientes y su interacci√≥n en un experimento. 

&lt;uw-blockquote&gt; En el ANOVA las variables independientes se denominan **factores**.


---

## Pero antes de seguir....

--

- ¬øSabes qu√© es una variable dependiente e independiente?
--

- ¬øQu√© es un factor y cu√°les son sus niveles?
--

- ¬øQu√© es una variable continua y una variable discreta?
--

- ¬øQu√© es una interacci√≥n entre factores?

---
## An√°lisis de varianza - ANOVA

&lt;uw-blockquote&gt; Cuando existe una √∫nica variable independiente se denomina **Anova de un factor** (one way anova, en ingl√©s), cuando son dos **Anova de dos v√≠as** y cuando son m√°s de dos, se denomina como **Anova factorial**.

---
# Pruebas param√©tricas y supuestos estad√≠sticos

Antes de comenzar, todas las pruebas estad√≠sticas tienen supuestos...

--
- ¬øYa conocen alguna prueba estad√≠stica?
--


- ¬øQu√© supuestos tienen estas pruebas?

---
# Pruebas param√©tricas 

&lt;uw-blockquote&gt;  Se conoce como estad√≠stica param√©trica a aquella que se basa en el muestreo de una poblaci√≥n con una distribuci√≥n conocida (**normal**) y con  par√°metros fijos (**media poblacional, varianza o desviaci√≥n est√°ndar**). 

---
# Pruebas param√©tricas


|VENTAJAS    | DESVENTAJAS     | 
|-------------------|-------|
| - Sensibles a rasgos de los datos recolectados  | - M√°s complicadas de calcular | 
| - Estimaciones probabil√≠sticas m√°s exactas       |- Solo se pueden aplicar si se cumplen sus supuestos   | 
| - Tienen una mayor eficiencia y poder estad√≠stico      | - Los datos que se pueden observar son limitados| 

---
# Pruebas param√©tricas

|TIPO    |   PRUEBA     | 
|:-------------------:|:-------:|
| Comparaci√≥n de 2 grupos	  |   t de Student/Welch  | 
| Comparaci√≥n de &gt;2 grupos       | **Anova**   | 
| Correlaci√≥n de dos variables     | Coeficiente de Pearson| 
| Variables cualitativas     | Prueba de Z| 

---
# Pruebas param√©tricas y supuestos estad√≠sticos

Los supuestos de las pruebas param√©tricas en general son:
--

- Distribuci√≥n conocida (**normal**): visual y pruebas num√©ricas.
--

- Homocedasticidad: visual y pruebas num√©ricas.
--

- Otros: tama√±o de la muestra, variables cuantitativas o continuas, outliers, aleatoriedad, independencia de las observaciones, linealidad. 

.

.center[*** Cada tipo de prueba param√©trica tiene sus propios supuestos***]
---


## Supuestos estad√≠sticos del ANOVA

Los supuestos del ANOVA son:

- **Distribuci√≥n normal de los residuales:** `\(\epsilon_{i,j} ‚àº N(0,\sigma^2)\)`. Es decir, los errores (residuos) deben distribuirse normalmente con media 0 y varianza constante.

- **Homocedasticidad**: Todos los grupos comparten la misma varianza poblacional `\(œÉ¬≤\)`.

- **Aleatoriedad e independencia**
 
- **Otros**: Mismo n√∫mero de observaciones por grupos, variable dependiente continua y variable independiente con tres o m√°s grupos o niveles. 

---

### Distribuci√≥n normal: m√©todos visuales

.pull-left[



``` r
data_normal&lt;- rnorm(200)
hist(data_normal, col='steelblue', main='Normal')
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-5-1.png" alt="" style="display: block; margin: auto;" /&gt;
]
.pull-right[



``` r
data_no_normal&lt;- rexp(100, rate=3)
hist(data_no_normal, col='red', main='No normal')
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-7-1.png" alt="" style="display: block; margin: auto;" /&gt;
]
---
### Distribuci√≥n normal: m√©todos visuales

.pull-left[



``` r
plot(density(data_normal), main="Normal")
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-9-1.png" alt="" style="display: block; margin: auto;" /&gt;
]
.pull-right[


``` r
plot(density(data_no_normal), main="No Normal")
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-10-1.png" alt="" style="display: block; margin: auto;" /&gt;
]

---
### Distribuci√≥n normal: m√©todos visuales

.pull-left[



``` r
qqnorm(data_normal)
qqline(data_normal)
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-12-1.png" alt="" style="display: block; margin: auto;" /&gt;
]
.pull-right[


``` r
qqnorm(data_no_normal)
qqline(data_no_normal)
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-13-1.png" alt="" style="display: block; margin: auto;" /&gt;
]
---
### Distribuci√≥n normal: m√©todos num√©ricos

**Prueba de Shapiro‚ÄìWilk**

Hip√≥tesis

`\(ùêª_{0}\)`: Los datos provienen de una distribuci√≥n normal

`\(ùêª_{1}\)`: Los datos no provienen de una distribuci√≥n normal


`$$W = \frac{\left(\sum_{i=1}^{n} a_i x_{(i)} \right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}$$`
D√≥nde:
`\(x_{(i)}\)` = datos ordenados, `\(\bar{x}\)` = media muestral, `\(a_{i}\)` = constantes derivadas de la normal te√≥rica, `\(n\)` = tama√±o de muestra
---
### Distribuci√≥n normal: m√©todos num√©ricos

**Prueba de Kolmogorov‚ÄìSmirnov**

Hip√≥tesis

`$$ùêª_{0}: F(x) = F_{0}(x)$$` 

`$$ùêª_{1}: F(x) \neq F_{0}(x)$$` 
`\(F(x)\)` = distribuci√≥n acumulada de la muestra

`\(F_{0}(x)\)` = distribuci√≥n te√≥rica

$$
D = \sup_{x} \left| F_n(x) - F_0(x) \right|
$$
D√≥nde: `\(F_n(x)\)` es la funci√≥n emp√≠rica, `\(F_0(x)\)` es la funci√≥n te√≥rica y supp la mayor diferencia te√≥rica. 



---
### Distribuci√≥n normal: m√©todos num√©ricos
.pull-left[



``` r
shapiro.test(data_normal)
```

```
## 
## 	Shapiro-Wilk normality test
## 
## data:  data_normal
## W = 0.99076, p-value = 0.2298
```



``` r
ks.test(data_normal, "pnorm")
```

```
## 
## 	Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  data_normal
## D = 0.053155, p-value = 0.6243
## alternative hypothesis: two-sided
```
]
.pull-right[


``` r
shapiro.test(data_no_normal)
```

```
## 
## 	Shapiro-Wilk normality test
## 
## data:  data_no_normal
## W = 0.89131, p-value = 5.641e-07
```


``` r
ks.test(data_no_normal, "pnorm")
```

```
## 
## 	Asymptotic one-sample Kolmogorov-Smirnov test
## 
## data:  data_no_normal
## D = 0.50783, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided
```

]
---
### Probando heterocedasticidad
- M√©todos visuales = Pruebas estad√≠sticas de comparaci√≥n y modelos lineales

.pull-left[




``` r
data("ToothGrowth")
boxplot(len ~ supp, data=ToothGrowth, col=c("red", "blue"), main="Dientes")
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-20-1.png" alt="" style="display: block; margin: auto;" /&gt;

]
.pull-right[


``` r
data("iris")
boxplot(Petal.Width ~ Species, data=iris, col=c("pink", "purple", "cyan"), main="Flores")
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-21-1.png" alt="" style="display: block; margin: auto;" /&gt;

]
---
### Probando heterocedasticidad

.pull-left[

``` r
aggregate(len ~ supp, data = ToothGrowth, var)
```

```
##   supp      len
## 1   OJ 43.63344
## 2   VC 68.32723
```
Ratio

``` r
68.32 /  43.63
```

```
## [1] 1.565895
```

]
.pull-right[

``` r
aggregate(Petal.Width ~ Species, data = iris, var)
```

```
##      Species Petal.Width
## 1     setosa  0.01110612
## 2 versicolor  0.03910612
## 3  virginica  0.07543265
```
Ratio

``` r
r1&lt;-0.03910612 / 0.01110612 #versicolor vs setosa
r2&lt;-0.07543265 / 0.01110612 #virginca vs setosa
r3&lt;-0.07543264 / 0.03910612 #virginica vs versicolor
cbind(r1,r2,r3)
```

```
##            r1       r2       r3
## [1,] 3.521132 6.791989 1.928922
```
]
---
### Probando heterocedasticidad
.pull-left[

``` r
m1&lt;-lm(len ~ supp, data=ToothGrowth)
par(mfrow = c(1, 2))
plot(m1, which=c(1,3))
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-26-1.png" alt="" style="display: block; margin: auto;" /&gt;

]
.pull-right[


``` r
m2&lt;-lm(Petal.Width ~ Species, data=iris)
par(mfrow = c(1, 2))
plot(m2, which=c(1,3))
```

&lt;img src="Clase2-ANOVA_files/figure-html/unnamed-chunk-27-1.png" alt="" style="display: block; margin: auto;" /&gt;

]
---
### Probando heterocedasticidad

**Prueba F para igualdad de varianzas (2 grupos)**

Hip√≥tesis

$$
H_0: \sigma_1^2 = \sigma_2^2 \qquad
H_1: \sigma_1^2 \neq \sigma_2^2
$$
$$
F = \frac{s_1^2}{s_2^2}
$$

D√≥nde:

`\({s_1^2}\)` = varianza muestral del grupo 1

`\({s_2^2}\)` = varianza muestral del grupo 2

---
### Probando heterocedasticidad


``` r
var.test(len ~ supp, data = ToothGrowth) 
```

```
## 
## 	F test to compare two variances
## 
## data:  len by supp
## F = 0.6386, num df = 29, denom df = 29, p-value = 0.2331
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.3039488 1.3416857
## sample estimates:
## ratio of variances 
##          0.6385951
```

---
### Probando heterocedasticidad
Para m√°s de dos niveles

- **Prueba de Breusch‚ÄìPagan**: Eval√∫a si la varianza de los residuos depende de los predictores.

$$
H_0: \operatorname{Var}(\varepsilon_i) = \sigma^2
\qquad
$$

$$
BP = nR^2
$$

D√≥nde:

`\(n\)` = tama√±o de la muestra

`\(R^2\)` = coeficiente de determinaci√≥n de una regresi√≥n auxiliar
(residuos cuadrados contra los predictores)


---
### Probando heterocedasticidad



``` r
lmtest::bptest(m2) #sobre un modelo
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  m2
## BP = 25.099, df = 2, p-value = 3.546e-06
```


---
### Probando heterocedasticidad

- **Prueba de Levene**: Compara cu√°nto se dispersan los datos alrededor de su media  en cada grupo.

Si las dispersiones son similares ‚Üí homocedasticidad.

Hip√≥tesis: `\(H_{0}:\sigma^2 = \sigma^2_{1} = \sigma^2_{2} = ... = \sigma^2_{k}\)`

`$$Z_{ij} = |Y_{ij} - \bar{Y}_{i\cdot}|$$`

`\(Z_{ij}\)` = distancia absoluta del dato respecto a la media de su grupo

`$$F = \frac{MS_{\text{entre grupos}}}{MS_{\text{dentro de grupos}}}$$`


---
### Probando heterocedasticidad

``` r
library(car)
leveneTest(m2)
```

```
## Levene's Test for Homogeneity of Variance (center = median)
##        Df F value    Pr(&gt;F)    
## group   2  19.892 2.261e-08 ***
##       147                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


``` r
?fligner.test
```


---
# An√°lisis de varianza de una v√≠a
- El **ANOVA de una v√≠a** es el tipo de an√°lisis que se emplea cuando los datos no est√°n pareados y se quiere estudiar si existen diferencias significativas entre las medias de una variable aleatoria continua en los diferentes niveles de otra variable cualitativa o factor.

+ Las hip√≥tesis contrastadas en un ANOVA de un factor son:
  - `\(H_{0}\)` : No existen diferencias entre las medias de los grupos, es decir `\(\mu_{1}=\mu_{2}=....\mu_{k}\)`
  - `\(H_{1}\)` : Al menos un par de medias es significativamente diferente una de la otra


---
# An√°lisis de varianza de una v√≠a
+ El ANOVA de una v√≠a, crea una comparaci√≥n entre la varianza en los datos que provienen de las diferencias entre grupos y la varianza en los datos que provienen de las diferencias dentro de los grupos.

 - `\(H_{0}\)` : `\(\sigma^2_{entre} = 0\)`    `\(\rightarrow\)` `\(\sigma^2_{entre}\)` + `\(\sigma^2_{dentro}\)` =  `\(\sigma^2_{dentro}\)`
 
 - `\(H_{1}\)` : `\(\sigma^2_{entre} &gt; 0\)`   `\(\rightarrow\)` `\(\sigma^2_{entre}\)` + `\(\sigma^2_{dentro}\)` &gt;  `\(\sigma^2_{dentro}\)`
 
 
 
---
# An√°lisis de varianza de una v√≠a
 
La forma en que el ANOVA hace esta comparaci√≥n es evaluando las razones de las varianzas entre grupos y las varianzas dentro de los grupos:

- a nivel de poblaci√≥n, si la raz√≥n es igual a 1, entonces las dos cosas son iguales

- si la raz√≥n es mayor que uno, entonces la varianza entre grupos es al menos un poco mayor que 0 y esto lo conocemos como el **el estad√≠stico F**.
---
# An√°lisis de varianza de una v√≠a

### El estad√≠stico F se calcula as√≠: 

$$
`\begin{aligned}
F = \frac{\sigma^2_{entre}}{\sigma^2_{dentro}} = \frac{intervarianza}{intravarianza}= \frac{\frac{n\Sigma(\bar{x}_{k}-\bar{x})^2}{k-1}}{\frac{\Sigma(x_{k}-\bar{x_{k}})^2}{N-k}} = \frac{\frac{SCT}{k-1}}{\frac{SCE}{gl}}
\end{aligned}`
$$


siendo `\(k\)` los niveles, `\(N-k\)` y `\(k - 1\)` los grados de libertad y `\(SC\)` la suma de cuadrados del error (intravarianza) y de los tratamientos (intervarianza).


---
# An√°lisis de varianza de una v√≠a : Tabla

|Fuente de variaci√≥n|Suma de cuadrados|Grados de libertad|Cuadros promedios|F|
|:--------:|:---------------:|:----------------:||:--------------:||:-:|
|Entre Grupos|SCT|k-1|CMT = SCT/k-1|F=CMT/CME|
|Dentro de los grupos o Error|SCE|N-k|CME = SCE/N-k|
|Total|STT|N-1|

---
# Ejemplo aplicado

``` r
datos&lt;- data.frame(Tratamiento1=c(-3.10,0.18,-0.72,0.09,-1.66),
                  Tratamiento2=c(7.28,3.06,4.74,5.29,7.88),
                  Tratamiento3=c(0.12,5.51,5.72,5.93,6.56),
                  Tratamiento4=c(8.18,9.05,11.21,7.31,8.83))
```

| Tratamiento1 | Tratamiento2 | Tratamiento3 | Tratamiento4 |
|:------------:|:------------:|:------------:|:------------:|
|    -3.10     |     7.28     |     0.12     |     8.18     |
|     0.18     |     3.06     |     5.51     |     9.05     |
|    -0.72     |     4.74     |     5.72     |    11.21     |
|     0.09     |     5.29     |     5.93     |     7.31     |
|    -1.66     |     7.88     |     6.56     |     8.83     |
---
## Probemos los supuestos
.pull-left[
### Normalidad


``` r
ro1&lt;- datos$Tratamiento1-mean(as.matrix(datos))
ro2&lt;- datos$Tratamiento2-mean(as.matrix(datos))
ro3&lt;- datos$Tratamiento3-mean(as.matrix(datos))
ro4&lt;- datos$Tratamiento4-mean(as.matrix(datos))


shapiro.test(c(ro1,ro2, ro3, ro4))
```

```
## 
## 	Shapiro-Wilk normality test
## 
## data:  c(ro1, ro2, ro3, ro4)
## W = 0.93347, p-value = 0.1801
```
]
.pull-right[
### Homocedasticidad

``` r
library(tidyverse)
datost&lt;- datos %&gt;% pivot_longer(cols = everything(), names_to = "Tratamiento", values_to = "Valor")

lmtest::bptest(lm(Valor~Tratamiento, data = datost))
```

```
## 
## 	studentized Breusch-Pagan test
## 
## data:  lm(Valor ~ Tratamiento, data = datost)
## BP = 2.3472, df = 3, p-value = 0.5035
```
]


---
### Calculemos los grados de libertad

- Hay cuatro niveles entonces `\(k-1\)` = 3
- Hay cinco observaciones en cada grupo entonces `\(N - k\)` = (4*5)-3 = 16
- Los grados de libertad totales son `\(N - 1\)` = 20-1 = 19

### Calculemos SCT
SCT = `\(n\Sigma(\bar{x}_{k}-\bar{x})^2\)`

``` r
SCT1= 5*(mean(datos$Tratamiento1)-mean(as.matrix(datos)))^2
SCT2= 5*(mean(datos$Tratamiento2)-mean(as.matrix(datos)))^2
SCT3= 5*(mean(datos$Tratamiento3)-mean(as.matrix(datos)))^2
SCT4= 5*(mean(datos$Tratamiento4)-mean(as.matrix(datos)))^2

SCT= (SCT1+SCT2+SCT3+SCT4); SCT
```

```
## [1] 257.9391
```
 
---
### Calculemos SCE
.pull-left[SCE = `\(\Sigma(x_{k}-\bar{x_{k}})^2\)`

``` r
SCE1= sum((datos$Tratamiento1-mean(datos$Tratamiento1))^2)
SCE2= sum((datos$Tratamiento2-mean(datos$Tratamiento2))^2)
SCE3= sum((datos$Tratamiento3-mean(datos$Tratamiento3))^2)
SCE4= sum((datos$Tratamiento4-mean(datos$Tratamiento4))^2)

SCE = (SCE1+SCE2+SCE3+SCE4); SCE
```

```
## [1] 58.82228
```
]

### Calculemos STT 

.pull-right[
STT = `\(\Sigma(x_{k}-\bar{x})^2\)`

``` r
STT1= sum((datos$Tratamiento1-mean(as.matrix(datos)))^2)
STT2= sum((datos$Tratamiento2-mean(as.matrix(datos)))^2)
STT3= sum((datos$Tratamiento3-mean(as.matrix(datos)))^2)
STT4= sum((datos$Tratamiento4-mean(as.matrix(datos)))^2)

STT = (STT1+STT2+STT3+STT4); STT
```

```
## [1] 316.7614
```
]
---

.pull-left[
### Calculemos CMT

``` r
CMT=SCT/(4-1);CMT
```

```
## [1] 85.97971
```
### Calculemos CME

``` r
CME=SCE/(20-4);CME
```

```
## [1] 3.676393
```
]
.pull-right[
### Calculemos F


``` r
valor_F= CMT/CME; valor_F
```

```
## [1] 23.38698
```

### Calculemos el valor p

``` r
valor_p&lt;-pf(valor_F, df1=4-1, df2=20-4, lower.tail=FALSE); valor_p
```

```
## [1] 4.313444e-06
```
]
---
# Hag√°moslo en R

``` r
anova_R&lt;- aov(Valor~Tratamiento, data = datost)
summary(anova_R)    
```

```
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## Tratamiento  3 257.94   85.98   23.39 4.31e-06 ***
## Residuals   16  58.82    3.68                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
#### Comparando...

``` r
valor_F;valor_p
```

```
## [1] 23.38698
```

```
## [1] 4.313444e-06
```

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
